\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission


\usepackage{neurips_2023}



\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{amsmath}

\makeatletter
\newif\if@submission
\@submissionfalse

\makeatother
\title{Formatting Instructions For NeurIPS 2023}
\author {
  HU Gangfeng \\ 2022533025 \\ \texttt{hugf2022@shanghaitech.edu.cn}
  \And
  TENG Zhihao \\ 2022533050 \\ \texttt{tengzhh2022@shanghaitech.edu.cn}
  \And
  QIN Chao \\ 2022533137 \\\texttt{qinchao2022@shanghaitech.edu.cn}
}

\begin{document}


\maketitle


\begin{abstract}
  Improving classiﬁcation accuracy is a key issue to ad- vancing brain computer interface (BCI) research from lab- oratory to real world applications. 
This article presents a high accuracy EEG signal classiﬁcation method using sin- gle trial EEG signal to detect left and right ﬁnger move- ment. 
We apply an optimal temporal ﬁlter to remove  irrelevant signal and subsequently extract key features from spatial patterns of EEG signal to perform classiﬁcation. 
Speciﬁcally, the proposed method transforms the original EEG signal into a spatial pattern and applies the RBFfea- ture selection method to generate robust feature. 
Classiﬁcation is performed by the SVM and our experimental result shows that the classiﬁcation accuracy of the proposed method reaches 90\% as compared to the current reported best accuracy of 84\%.
\end{abstract}


\section{Introduction}

A brain-computer interface (BCI) is a communication system that does not depend on the brain's normal output pathways of peripheral nerves and muscles. At present, eletroencephalography(EEG) is one of the most prevailing signals used in non-invasive BCI systems.
There are various kinds of EEG based  BCIs  categorized by the signals used. Typical signals include slow cortical potential, rhythms, EEG (de)synchronization evoked by motor imagery, steady-state visual evoked poten- tial, P300 potential, etc. EEG signals evoked by limb move- ment or motor imagery are of interest to this paper.
The preparation, actual operation and mental imagina- tion of limb movements activate similar EEG changes at sensorimotor areas on the  scalp. When  such regions be- come activated, EEG activities display an amplitude atten- uation or event-related desynchronization (ERD). For in- stance, imagination of right-hand or left-hand movement


results in the most prominent ERD localized over the cor- responding sensorimotor cortex. However, ERD is subject- related,i.e. different subjects have different spatial localiza- tions of ERD. This leads to difﬁculty when extracting fea- tures for classiﬁcation.
Pfurtscheller et. al. [6] extracted motor imagery signals from C3 and C4 EEG Channels to build an online BCI sys- tem. The features presented to the classiﬁer were short-term power spectra in pre-deﬁne frequency bands. This system using a LVQ algorithm achieved an accuracy of approxi- mately 80% for 3 subjects.
Studies  showed  that  the  position  of  ERD  may  vary from subject to subject, and are not necessarily located be- neath  electrode  positions  C3  and  C4  [5].  As  such,  us- ing more channels of signals may improve performance.
Mller-Gerking et. al. [4] proposed to use Common Spa-
tial Patterns (CSP) for the classiﬁcation of motor execution or imagery  signals. The CSP method resulted in  signiﬁ- cant improvement to performances  as compared to their previous work in  [6].
In this paper, we combined CSP and Principal Compo- nent Analysis (PCA) to improve the CSP feature classiﬁ- cation. The resulted transformation is equivalent to a set of spatial ﬁlters optimized to distinguish between the left and right hand movement or motor imagery. In addition, temporal ﬁltering was applied to reduce noise. In the past, the selection of frequency bands was limited to a few pre- deﬁned bands [4, 5]. In this paper, we investigated the ef- fects of temporal  ﬁltering for  speciﬁc  subject by  an ex- haustive search over all the frequency bands. We showed that classiﬁcation performance could be improved signiﬁ- cantly by applying proper band-pass ﬁlter. To further en- hance recognition accuracy, a Radial Basis Function (RBF) based feature selection and generation algorithm  [3] was adapted. We applied the Orthogonal Least Square (OLS) algorithm [3] to feature selection and generation. Using a Support Vector Machine (SVM) classiﬁer on the features found, we achieved 90\% accuracy on a self-paced ﬁnger- taping dataset, the current best result in the literature on this
dataset.
The organization of the paper is as follows. Section 2 in- troduces the feature extraction by the combination of CSP and PCA. Section 3 presents the feature selection and gen- eration algorithms. Section 4 discusses the effects of differ- ent parameters on the recognition performance and present comparative experiment results. Finally, we conclude our paper and discuss some future work.


\section{Dataset}
In our study, we adopt the widely used Sleep-EDF database, and mainly dig into the Sleep Cassette(SC) part. 
It contains 153 PSG recordings belonging to 82 subjects. 
For 71 of them, the recording of the first night and the second night are available. 
As for each PSG recording, we mainly take four signals into consideration: 2 EEG(Fpz-CZ and Pz-Cz), 1 EOG (horizontal), and 1 EMG (submental chin). 
The EOG and EMG channels are sampled at 100Hz. Since full EMG recordings are not available, we only adopt 2 EEG and 1 EOG as input. 
Each 30-second epoch of the recordings was manually labelled by sleep experts according to the R\&K standard [1] into one of eight categories \{W, N1, N2, N3, N4, REM, MOVEMENT, UNKNOWN\}. 
As this database has been used differently in literature, it should be stressed that only the in-bed parts (from lights off time to lights on time) of the recordings were used as recommended in [2],[3],[4].

\section{Evaluation Method}
In order to evaluate the models in terms of multiclass classification accuracy, there are mainly three approaches: macro F1-score(MF1), overall accuracy(ACC), Cohen's Kappa coefficient($\kappa$). We split the PSGs into testing set, containing 25\% of data, and the training set, containing the rest 75\%. For all the traditional machine learning models and deep learning models, we use the training set to train the models and use the testing set to check their performance. We compare the output of the models and the ground truth using MF1, ACC and $\kappa$ with the following formulas:
$$
\begin{aligned}
N&=\text{the number of testing samples}\\
k&=\text{the number of catagories}\\
CFM_{i,j}&=\text{the number of samples whose real output is j but prediction is i}\\
TP_i&=CFM_{i,i}\quad FP_j=\sum_{i\neq j}CFM_{i,j}\quad FN_i=\sum_{j\neq i}CFM_{i,j}\\
ACC&=\frac{\sum_{i=1}^{k}TP_i}{N}\\
pre&=\frac{1}{k}\sum_{i=1}^k\frac{TP_i}{TP_i+FP_i}\quad rec=\frac{1}{k}\sum_{i=1}^k\frac{TP_i}{TP_i+FN_i}\\
MF1&=\frac{2*pre*rec}{pre+rec}\\
p_o&=ACC\quad p_e=\frac{\sum_{i=1}^{k}(\sum_{j=1}^kCFM_{i,j})(\sum_{j=1}^kCFM_{j,i})}{N^2}\\
\kappa&=\frac{p_o-p_e}{1-p_e}
\end{aligned}
$$

\section{Results}


[1] J. A. Hobson, “A manual of standardized terminology, techniques and
scoring system for sleep stages of human subjects,” Electroencephalography Clin. Neurophysiol., vol. 26, no. 6, 1969, Art. no. 644.

[2] H. Phan et al., “Joint classification and prediction CNN framework for
automatic sleep stage classification,” IEEE Trans Biomed Eng, vol. 66,
no. 5, pp. 1285–1296, 2019.

[3] O. Tsinalis et al., “Automatic sleep stage scoring with single-channel
EEG using convolutional neural networks,” arXiv:1610.01683, 2016.

[4]H. Phan et al., “DNN filter bank improves 1-max pooling CNN for
single-channel EEG automatic sleep stage classification,” in Proc.
EMBC, 2018, pp. 453–456.

[5]

\end{document}